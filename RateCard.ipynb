{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Rate Card Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_df = pd.read_excel(\"./NYJ-Data/Broadcast_Exposures.xlsx\") # broadcast exposures\n",
    "vb_df = pd.read_excel(\"./NYJ-Data/Videoboard_Features.xlsx\") # videoboard features\n",
    "sm_df = pd.read_csv(\"./NYJ-Data/AllContentSeriesPosts.csv\") # social media posts\n",
    "\n",
    "# convert Instragram Stories Tap Count to Engagement Rate\n",
    "for i, row in sm_df.iterrows():\n",
    "    if row['ServiceType'] == 'Instagram Story':\n",
    "        new_val = row['TapBackwardCount']/row['TapForwardCount']\n",
    "        sm_df.at[i, 'EngagementRate'] = new_val\n",
    "\n",
    "sm_df.dropna(subset= ['EngagementRate'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "bc_df = bc_df[['Asset', 'Audience', 'Media_Value_USD', 'Seen_Hits_Seconds']]\n",
    "vb_df = vb_df[['Asset', 'Video_Total_Seconds', 'Logo_Average_Clarity', 'Logo_Average_Size', 'Logo_Total_Seconds']]\n",
    "sm_df = sm_df[['ServiceType','Content_Series_Name', 'EngagementRate', 'PostValue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max Normalization\n",
    "\n",
    "df = bc_df.drop('Asset', axis=1)\n",
    "df_norm = (df - df.min()) / (df.max() - df.min())\n",
    "bc_df = pd.concat((bc_df['Asset'], df_norm), axis=1)\n",
    "\n",
    "df = vb_df.drop('Asset', axis=1)\n",
    "df_norm = (df - df.min()) / (df.max() - df.min())\n",
    "vb_df = pd.concat((vb_df['Asset'], df_norm), axis=1)\n",
    "\n",
    "df = sm_df.drop(['Content_Series_Name', 'ServiceType'], axis=1)\n",
    "df_norm = (df - df.min()) / (df.max() - df.min())\n",
    "sm_df = pd.concat((sm_df[['Content_Series_Name', 'ServiceType']], df_norm), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "T_VAL = 1.96 # t-value for 95% confidence interval\n",
    "OUTLIER = 50 # threshold for outlier removal determined by looking at distribution of videoboard, broadcast, and social media counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VideoBoard Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VB_Scoring(sec_weight, clarity_weight, size_weight):\n",
    "    \"\"\"\n",
    "        Calculate the score for videoboard assets\n",
    "        Input:  weights for videoboard variables: Video_Total_Seconds, Logo_Average_Clarity, Logo_Average_Size\n",
    "        Output: Score for videoboard assets\n",
    "    \"\"\"\n",
    "    vb_vars = vb_df.groupby('Asset').agg(['count', 'mean', 'std']).reset_index()\n",
    "\n",
    "    # filter out series that don't meet median threshold\n",
    "    median_count = vb_vars['Video_Total_Seconds'].where(vb_vars['Video_Total_Seconds']['count'] < OUTLIER)['count'].median()\n",
    "\n",
    "    vid_sec = vb_vars[['Asset', 'Video_Total_Seconds']].where(vb_vars['Video_Total_Seconds']['count'] >= median_count).dropna()\n",
    "    logo_sec = vb_vars[['Asset', 'Logo_Total_Seconds']].where(vb_vars['Logo_Total_Seconds']['count'] >= median_count).dropna()\n",
    "    clarity = vb_vars[['Asset', 'Logo_Average_Clarity']].where(vb_vars['Logo_Average_Clarity']['count'] >= median_count).dropna()\n",
    "    size = vb_vars[['Asset', 'Logo_Average_Size']].where(vb_vars['Logo_Average_Size']['count'] >= median_count).dropna()\n",
    "\n",
    "    # rename columns\n",
    "    vid_sec.columns = vid_sec.columns.map(' '.join)\n",
    "    logo_sec.columns = logo_sec.columns.map(' '.join)\n",
    "    clarity.columns = clarity.columns.map(' '.join)\n",
    "    size.columns = size.columns.map(' '.join)\n",
    "\n",
    "    # recombine into one dataframe\n",
    "    recombined = pd.merge(logo_sec, clarity, on='Asset ')\n",
    "    recombined = pd.merge(recombined, size, on='Asset ')\n",
    "    addSeries = vb_vars[vb_vars.Asset.str.contains('Did You Know?')]\n",
    "    addSeries.columns = addSeries.columns.map(' '.join)\n",
    "    recombined = recombined.append(addSeries) ## add this series to connect social media\n",
    "\n",
    "    Scores = pd.DataFrame(columns=['Asset', 'Low', 'Average', 'High'])\n",
    "\n",
    "    # calculate 95% confidence interval scores\n",
    "    for index,row in recombined.iterrows():\n",
    "        low = sec_weight * (row['Logo_Total_Seconds mean'] - T_VAL*row['Logo_Total_Seconds std']) + clarity_weight * (row['Logo_Average_Clarity mean'] - T_VAL*row['Logo_Average_Clarity std'] )+ size_weight * (row['Logo_Average_Size mean'] - T_VAL*row['Logo_Average_Size std'])\n",
    "        average = sec_weight* row['Logo_Total_Seconds mean'] + clarity_weight* row['Logo_Average_Clarity mean'] + size_weight * row['Logo_Average_Size mean']\n",
    "        high = sec_weight * (row['Logo_Total_Seconds mean'] + T_VAL*row['Logo_Total_Seconds std']) + clarity_weight * (row['Logo_Average_Clarity mean'] + T_VAL*row['Logo_Average_Clarity std'] )+ size_weight * (row['Logo_Average_Size mean'] + T_VAL*row['Logo_Average_Size std'])\n",
    "\n",
    "        Scores.loc[index] = [row['Asset '], low, average, high]\n",
    "    \n",
    "    # adjust all scores to get rid of negative values\n",
    "    min_score = Scores['Low'].min()\n",
    "    Scores['Low'] = Scores['Low'] + abs(min_score) + abs(Scores['Low'].mean())\n",
    "    Scores['Average'] = Scores['Average'] + abs(min_score) + abs(Scores['Low'].mean())\n",
    "    Scores['High'] = Scores['High'] + abs(min_score) + abs(Scores['Low'].mean())\n",
    "\n",
    "    # sort scores for debugging purposes\n",
    "    Scores = Scores.sort_values(by='Average', ascending=False)\n",
    "\n",
    "    return Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcast Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BC_Scoring(aud_weight=1.5, val_weight=2, hit_weight=.75):\n",
    "    \"\"\"\n",
    "        Calculate the score for broadcast assets\n",
    "        Input:  weights for broadcast variables: Audience, Media_Value_USD, Seen_Hits_Seconds\n",
    "        Output: Score for broadcast assets\n",
    "\n",
    "    \"\"\"\n",
    "    bc_vars = bc_df.groupby('Asset').agg(['count', 'mean', 'std']).reset_index()\n",
    "\n",
    "    # filter out series that don't meet median threshold\n",
    "    median_count = bc_vars['Audience'].where(bc_vars['Audience']['count'] < OUTLIER)['count'].median()\n",
    "\n",
    "    audience = bc_vars[['Asset', 'Audience']].where(bc_vars['Audience']['count'] >= median_count).dropna()\n",
    "    value = bc_vars[['Asset', 'Media_Value_USD']].where(bc_vars['Media_Value_USD']['count'] >= median_count).dropna()\n",
    "    hits = bc_vars[['Asset', 'Seen_Hits_Seconds']].where(bc_vars['Seen_Hits_Seconds']['count'] >= median_count).dropna()\n",
    "\n",
    "    # rename columns\n",
    "    audience.columns = audience.columns.map(' '.join)\n",
    "    value.columns = value.columns.map(' '.join)\n",
    "    hits.columns = hits.columns.map(' '.join)\n",
    "\n",
    "    # recombine into one dataframe\n",
    "    recombined = pd.merge(audience, value, on='Asset ')\n",
    "    recombined = pd.merge(recombined, hits, on='Asset ') \n",
    "\n",
    "    Scores = pd.DataFrame(columns=['Asset', 'Low', 'Average', 'High'])\n",
    "\n",
    "    # calculate 95% confidence interval scores\n",
    "    for index, row in recombined.iterrows():\n",
    "        low = aud_weight * (row['Audience mean'] - T_VAL * row['Audience std']) + val_weight * (row['Media_Value_USD mean'] - T_VAL * row['Media_Value_USD std'])+ hit_weight * (row['Seen_Hits_Seconds mean'] - T_VAL * row['Seen_Hits_Seconds std'])\n",
    "        average = aud_weight *row['Audience mean'] + val_weight * row['Media_Value_USD mean'] + hit_weight * row['Seen_Hits_Seconds mean']\n",
    "        high = aud_weight * (row['Audience mean'] + T_VAL * row['Audience std']) + val_weight * (row['Media_Value_USD mean'] + T_VAL * row['Media_Value_USD std']) + hit_weight * (row['Seen_Hits_Seconds mean'] + T_VAL * row['Seen_Hits_Seconds std'])\n",
    "        \n",
    "        Scores.loc[index] = [row['Asset '], low, average, high]\n",
    "    \n",
    "    # adjust all scores to get rid of negative values\n",
    "    min_score = Scores['Low'].min()\n",
    "    Scores['Low'] = Scores['Low'] + abs(min_score) + abs(Scores['Low'].mean())\n",
    "    Scores['Average'] = Scores['Average'] + abs(min_score) + abs(Scores['Low'].mean())\n",
    "    Scores['High'] = Scores['High'] + abs(min_score) + abs(Scores['Low'].mean())\n",
    "\n",
    "    # sort scores for debugging purposes\n",
    "    Scores = Scores.sort_values(by='Average', ascending=False)\n",
    "    \n",
    "    return Scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Social Media Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SM_Scoring(val_weight, eng_weight):\n",
    "    \"\"\"\n",
    "        Calculate the score for social media assets\n",
    "        Input:  weights for social media variables: Media_Value_USD, Engagement\n",
    "        Output: Score for social media assets\n",
    "    \"\"\"\n",
    "    sm_vars = sm_df.groupby('Content_Series_Name').agg(['count', 'mean', 'std']).reset_index()\n",
    "\n",
    "    # filter out series that don't meet median threshold\n",
    "    median_count = sm_vars['EngagementRate'].where(sm_vars['EngagementRate']['count'] < OUTLIER)['count'].median()\n",
    "\n",
    "    eng_rate = sm_vars[['Content_Series_Name', 'EngagementRate']].where(sm_vars['EngagementRate']['count'] >= median_count).dropna()\n",
    "    post_value = sm_vars[['Content_Series_Name', 'PostValue']].where(sm_vars['PostValue']['count'] >= median_count).dropna()\n",
    "\n",
    "    # rename columns\n",
    "    eng_rate.columns = eng_rate.columns.map(' '.join)\n",
    "    post_value.columns = post_value.columns.map(' '.join)\n",
    "\n",
    "    # recombine into one dataframe\n",
    "    recombined = pd.merge(eng_rate, post_value, on='Content_Series_Name ')\n",
    "    addSeries = sm_vars[sm_vars['Content_Series_Name'].str.contains('Did You Know?')]\n",
    "    addSeries.columns = addSeries.columns.map(' '.join)\n",
    "    recombined =recombined.append(addSeries, ignore_index = True) ## add this series to connect videoboard\n",
    "\n",
    "    Scores = pd.DataFrame(columns=['Asset', 'Low', 'Average', 'High'])\n",
    "\n",
    "    # calculate 95% confidence interval scores\n",
    "    for index, row in recombined.iterrows():\n",
    "        low =  eng_weight * (row['EngagementRate mean'] - T_VAL * row['EngagementRate std']) + val_weight * (row['PostValue mean'] - T_VAL * row['PostValue std'])\n",
    "        average = eng_weight * (row['EngagementRate mean']) + val_weight * (row['PostValue mean'])\n",
    "        high = eng_weight * (row['EngagementRate mean'] + T_VAL * row['EngagementRate std']) + val_weight * (row['PostValue mean'] + T_VAL * row['PostValue std'])\n",
    "\n",
    "        Scores.loc[index] = [row['Content_Series_Name '], low, average, high]\n",
    "    \n",
    "    # adjust all scores to get rid of negative values\n",
    "    min_score = Scores['Low'].min()\n",
    "    Scores['Low'] = Scores['Low'] + abs(min_score) + abs(Scores['Low'].mean())\n",
    "    Scores['Average'] = Scores['Average'] + abs(min_score) + abs(Scores['Low'].mean())\n",
    "    Scores['High'] = Scores['High'] + abs(min_score) + abs(Scores['Low'].mean())\n",
    "\n",
    "    # sort scores for debugging purposes\n",
    "    Scores = Scores.sort_values(by='Average', ascending=False)\n",
    "\n",
    "    return Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pricing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BC_Pricing(Scores, initPrice):\n",
    "    \"\"\"\n",
    "        Calculate the price for broadcast assets\n",
    "        Input:  scores for broadcast assets, price for broadcast assets\n",
    "        Output: price dataframe for broadcast assets\n",
    "    \"\"\"\n",
    "    # Prices\n",
    "    Prices = pd.DataFrame(columns=['Asset', 'Bronze Tier', 'Silver Tier', 'Gold Tier'])\n",
    "\n",
    "    # static signage was the most closely related product to our market research\n",
    "    initScore = Scores[Scores['Asset'] == 'Static Signage']['Average'].values[0]\n",
    "\n",
    "    # calculate price for each tier, format it to round to the nearest dollar\n",
    "    for index, row in Scores.iterrows():\n",
    "        low = \"{:,}\".format(int((row['Low']/initScore) * initPrice))\n",
    "        average = \"{:,}\".format(int((row['Average']/initScore) * initPrice))\n",
    "        high = \"{:,}\".format(int((row['High']/initScore) * initPrice))\n",
    "        \n",
    "        Prices.loc[index] = [row['Asset'], low, average, high]\n",
    "\n",
    "    return Prices, int(Prices[Prices['Asset'] == 'Static Signage']['Silver Tier'].values[0].replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VB_Pricing(Scores, initPrice):\n",
    "    \"\"\"\n",
    "        Calculate the price for video board assets\n",
    "        Input:  scores for video board assets, price for video board assets\n",
    "        Output: price dataframe for video board assets\n",
    "    \"\"\"\n",
    "    # Prices\n",
    "    Prices = pd.DataFrame(columns=['Asset', 'Bronze Tier', 'Silver Tier', 'Gold Tier'])\n",
    "\n",
    "    initScore = Scores['Average'].mean() # average of the average video board scores\n",
    "\n",
    "    # calculate price for each tier, format it to round to the nearest dollar\n",
    "    for index, row in Scores.iterrows():\n",
    "        low = \"{:,}\".format(int((row['Low']/initScore) * initPrice))\n",
    "        average = \"{:,}\".format(int((row['Average']/initScore) * initPrice))\n",
    "        high = \"{:,}\".format(int((row['High']/initScore) * initPrice))\n",
    "        \n",
    "        Prices.loc[index] = [row['Asset'], low, average, high]\n",
    "\n",
    "    return Prices, int(Prices[Prices['Asset'] == 'Did You Know']['Silver Tier'].values[0].replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SM_Pricing(Scores, initPrice):\n",
    "    \"\"\"\n",
    "        Calculate the price for social media assets\n",
    "        Input:  scores for social media assets, price for social media assets\n",
    "        Output: price dataframe for social media assets\n",
    "    \"\"\"\n",
    "    # Prices\n",
    "    Prices = pd.DataFrame(columns=['Asset', 'Bronze Tier', 'Silver Tier', 'Gold Tier'])\n",
    "    \n",
    "    initScore = Scores[Scores['Asset']== 'Did You Know']['Average'].values[0] # Did You Know connects social media to video board\n",
    "\n",
    "    # calculate price for each tier, format it to round to the nearest dollar\n",
    "    for index, row in Scores.iterrows():\n",
    "        low = \"{:,}\".format(int((row['Low']/initScore) * initPrice))\n",
    "        average = \"{:,}\".format(int((row['Average']/initScore) * initPrice))\n",
    "        high = \"{:,}\".format(int((row['High']/initScore) * initPrice))\n",
    "        \n",
    "        Prices.loc[index] = [row['Asset'], low, average, high]\n",
    "\n",
    "    return Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_Pricing(bc_prices, vb_prices, sm_prices):\n",
    "    \"\"\"\n",
    "        Calculate the overall price for each asset\n",
    "        Input:  prices for broadcast assets, prices for video board assets, prices for social media assets\n",
    "        Output: price dataframe for each asset category\n",
    "    \"\"\"\n",
    "    # Prices\n",
    "    \n",
    "    bc = bc_prices.copy()\n",
    "    bc.drop(['Asset'], axis=1, inplace=True)\n",
    "    bc = bc.apply(lambda x: x.str.replace(',','').astype(int), axis=0)\n",
    "\n",
    "    vb = vb_prices.copy()\n",
    "    vb.drop(['Asset'], axis=1, inplace=True)\n",
    "    vb = vb.apply(lambda x: x.str.replace(',','').astype(int), axis=0)\n",
    "    \n",
    "    sm = sm_prices.copy()\n",
    "    sm.drop(['Asset'], axis=1, inplace=True)\n",
    "    sm = sm.apply(lambda x: x.str.replace(',','').astype(int), axis=0)\n",
    "\n",
    "    Prices = pd.DataFrame(columns=['Asset Category', 'Bronze Tier', 'Silver Tier', 'Gold Tier'], \n",
    "                          data=[['Broadcast', \"{:,}\".format(int(bc['Bronze Tier'].mean())), \"{:,}\".format(int(bc['Silver Tier'].mean())), \"{:,}\".format(int(bc['Gold Tier'].mean()))], \n",
    "                                ['Video Board', \"{:,}\".format(int(vb['Bronze Tier'].mean())), \"{:,}\".format(int(vb['Silver Tier'].mean())),  \"{:,}\".format(int(vb['Gold Tier'].mean()))],\n",
    "                                ['Social Media',  \"{:,}\".format(int(sm['Bronze Tier'].mean())),  \"{:,}\".format(int(sm['Silver Tier'].mean())),  \"{:,}\".format(int(sm['Gold Tier'].mean()))]])\n",
    "    return Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jets ranked 8th most profitable on all sites\n",
    "So an assumption was made to make the static signage cost 525,000 based on a report saying  \n",
    "the average cost of advertising is a little under the above amount.\n",
    "The report stated the range was 250-500,000 and that it would increase by 20% in the next year.\n",
    "We increased that range by 20% to be 300-600,000 and got the 75th percentile of that to arrive \n",
    "at 525,000 .\n",
    "\n",
    "- https://www.sportskeeda.com/nfl/most-profitable-nfl-franchises-2021#\n",
    "- https://www.cbssports.com/nfl/news/most-valuable-nfl-franchises-revealed-cowboys-and-patriots-top-2021-ranking-bills-and-bengals-at-the-bottom/\n",
    "- https://www.forbes.com/sites/mikeozanian/2021/08/05/the-nfls-most-valuable-teams-2021-average-team-value-soars-to-35-billion-as-league-shrugs-off-pandemic-year/?sh=53fa6e24654e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prices(initPrice= 525000, # https://www.sportico.com/business/sponsorship/2021/sports-sponsorship-media-price-hike-1234645336/ \n",
    "                post_value_weight=1, engagement_rate_weight=.75, # Social Media Weights\n",
    "                audience_weight=1, value_weight=.75, hit_seconds_weight=.5, # Broadcast Weights\n",
    "                seconds_weight=.5, clarity_weight=.75, size_weight= 1): # Video Board Weights\n",
    "    \"\"\"\n",
    "        Get the prices for the assets\n",
    "        Input:  None\n",
    "        Output: Dataframe with prices for assets\n",
    "    \"\"\"\n",
    "\n",
    "    vb_scores = VB_Scoring(seconds_weight, clarity_weight, size_weight)\n",
    "    bc_scores = BC_Scoring(audience_weight, value_weight, hit_seconds_weight)\n",
    "    sm_scores = SM_Scoring(post_value_weight, engagement_rate_weight)\n",
    "\n",
    "    \n",
    "    bc_prices, initVBPrice = BC_Pricing(bc_scores, initPrice)\n",
    "    vb_prices, initSMPrice = VB_Pricing(vb_scores, initVBPrice)\n",
    "    sm_prices = SM_Pricing(sm_scores, initSMPrice)\n",
    "    overall_prices = overall_Pricing(bc_prices, vb_prices, sm_prices)\n",
    "\n",
    "    return [overall_prices, bc_prices, vb_prices, sm_prices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Asset Category Bronze Tier Silver Tier Gold Tier\n",
      "0      Broadcast     182,369     453,458   644,145\n",
      "1    Video Board     209,451     437,499   520,421\n",
      "2   Social Media     124,701     303,104   399,918\n",
      "\n",
      "               Asset Bronze Tier Silver Tier Gold Tier\n",
      "15        Videoboard     201,667     607,575   933,081\n",
      "12   SNY Entitlement     329,754     527,405   644,653\n",
      "0           Ad Tower     114,084     509,199   823,911\n",
      "5                GIP     118,054     489,516   780,575\n",
      "6         LED Ribbon     101,967     487,621   792,872\n",
      "4        Cornerstone     116,853     459,442   721,629\n",
      "7   LED Tunnel Cover     113,734     446,413   698,690\n",
      "14    Static Signage     122,359     437,500   672,238\n",
      "8   LED Tunnel cover     116,614     434,831   672,645\n",
      "2    CBS Entitlement     275,856     433,718   511,178\n",
      "9   On-Field Product     122,975     431,688   659,999\n",
      "10    Press Backdrop     115,636     422,982   649,925\n",
      "3        CBS Feature     275,100     410,746   465,989\n",
      "1      CBS Billboard     281,655     406,817   451,577\n",
      "13       SNY Feature     259,143     375,279   411,013\n",
      "11     SNY Billboard     252,468     374,611   416,351\n",
      "\n",
      "                             Asset Bronze Tier Silver Tier Gold Tier\n",
      "23                    Lounge Promo     302,348     625,059   802,644\n",
      "10                         Fan Cam     116,571     545,688   829,678\n",
      "9                  Evacuation Plan      85,839     536,915   842,866\n",
      "43                Wave Your Towels     308,382     508,823   564,139\n",
      "41                    Vertical Bar     208,080     497,128   641,051\n",
      "1                 2 Minute Warning     305,837     492,993   535,023\n",
      "24                       Lucky Row     250,427     492,263   588,974\n",
      "18                  Helmet Shuffle     271,959     473,971   530,858\n",
      "36                    T-Shirt Toss     300,809     469,818   493,700\n",
      "5                      CBS 2 Promo      89,093     467,319   700,419\n",
      "2                         Ad Tower     176,861     467,040   612,093\n",
      "35                    Social Media     190,102     463,180   591,132\n",
      "34                          Skycam      64,326     455,738   702,025\n",
      "13                    Did You Know     245,395     444,937   499,352\n",
      "39                      The Island     239,751     444,005   503,134\n",
      "17               HS Player of Week     214,482     443,687   527,766\n",
      "25           Make Noise / Get Loud     250,609     442,772   489,810\n",
      "11                 Fantasy Leaders     218,655     441,329   518,877\n",
      "16               Group of the Game     202,223     439,253   531,157\n",
      "44               Welcome Back Fans     168,696     438,426   563,029\n",
      "19                        Holidays     277,713     435,651   448,463\n",
      "37                 Tackle Bullying     268,581     433,607   453,508\n",
      "3                    All-Pets Team     262,068     433,273   459,352\n",
      "26                         Matchup     165,798     430,629   550,335\n",
      "0                              1JD     268,618     430,183   446,624\n",
      "4                Around the League     163,668     429,947   551,100\n",
      "31                    Player Stats     227,974     423,816   474,532\n",
      "22                      Logo Flash     153,410     421,465   544,394\n",
      "29                    NFT Giveaway     220,225     417,870   470,389\n",
      "38                      Team Stats     242,369     417,703   447,911\n",
      "20                        Jets App     216,329     411,825   462,195\n",
      "32                          Replay     194,837     409,921   479,880\n",
      "6                        Cash Free     252,501     407,176   416,724\n",
      "15                   Group Tickets     213,124     405,624   452,998\n",
      "30                  Next Home Game     180,109     405,309   485,383\n",
      "28              My Cause My Cleats     206,033     403,702   456,245\n",
      "27              Merch Item of Game     219,987     396,016   426,919\n",
      "7            Crucial Catch / 50 50     158,137     394,532   485,802\n",
      "33                        Schedule     213,753     394,335   429,792\n",
      "14               Food Item of Game     226,164     392,446   413,603\n",
      "8                  Down & Distance     216,603     385,144   408,558\n",
      "40          Upstander of the Month     166,433     365,624   419,689\n",
      "42                       Watermark     183,677     363,707   398,612\n",
      "21  Jets Gameday with Robert Saleh     174,249     361,399   403,422\n",
      "12                      First Down     142,512     326,231   364,824\n",
      "\n",
      "                 Asset Bronze Tier Silver Tier Gold Tier\n",
      "67        Did You Know     196,114     444,937   612,171\n",
      "65      Victory Speech      43,114     396,170   667,637\n",
      "38  My Cause My Cleats     101,800     376,717   570,046\n",
      "10         Celebrities      90,903     340,640   508,788\n",
      "52                ROTW      55,751     337,699   538,059\n",
      "..                 ...         ...         ...       ...\n",
      "18         Friday Mood     170,735     261,726   271,130\n",
      "4          3 Takeaways     172,809     261,043   267,688\n",
      "16          First Down     168,833     260,641   270,862\n",
      "28           Inactives     161,758     259,001   274,656\n",
      "3      3 Stats to Know     168,060     257,743   265,839\n",
      "\n",
      "[68 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prints out pricing for each asset category\n",
    "x = get_prices()\n",
    "\n",
    "for i in x:\n",
    "    print(i)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
